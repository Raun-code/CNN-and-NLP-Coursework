
# ğŸ§  AI Coursework Repository â€“ CNN Presentation & NLP Project

This repository contains two major components of MSc Data Science coursework:

* ğŸ“½ï¸ A **presentation on Convolutional Neural Networks (CNNs)**
* ğŸ“˜ A **Natural Language Processing (NLP) application and report**

Both components demonstrate the integration of machine learning theory with practical implementation using real-world datasets and scholarly research.

---

## ğŸ¤ Part 1: CNN Presentation

### ğŸ“Œ Overview

* **Topic**: Convolutional Neural Networks (CNNs)
* **Format**: 5-minute video presentation + PDF slides
* **Objective**: Explain CNN fundamentals, explore a research paper using CNNs, discuss an ethical issue, and reflect on personal lab experience

### ğŸ“š Key Presentation Components

* **1. What is a CNN?**

  * Convolutional layers, ReLU activation, max-pooling, flattening
  * Dropout regularisation and fully connected layers
* **2. Ethical Issue**

  * Discussed real-world risks such as bias in facial recognition
* **3. Research Paper**

  * Sourced from the university library
  * Described research goals, dataset, CNN design, and results
* **4. Why CNN?**

  * Justification of CNN for visual/spatial pattern recognition tasks
* **5. Visualisations**

  * CNN architecture diagram
  * Visual outputs from the paper (e.g. confusion matrix, sample predictions)
* **6. Personal Reflection**

  * Brief commentary on hands-on CNN implementation in lab (e.g. MNIST digit recognition)

---

## ğŸ“˜ Part 2: NLP Application & Report

### ğŸ“Œ Overview

* **Goal**: Build and evaluate an NLP system using both traditional and deep learning models
* **Deliverables**:

  * Jupyter Notebook with full code, visualisations, and results
  * 3,000-word report (no code) with analysis, discussion, and evaluations

### âš™ï¸ Methodology

#### âœ… Problem Statement & Context

* Importance of NLP in domain (e.g., healthcare, social media, finance)
* Background literature on similar applications

#### ğŸ¯ SMART Objectives

* Defined clear, measurable goals grounded in real-world needs

#### ğŸ“‚ Dataset

* Publicly sourced or provided dataset
* Dataset description: size, class distribution, text characteristics
* Data issues and cleaning (e.g., stopwords, tokenisation, class imbalance)

#### ğŸ“Š Exploratory Data Analysis (EDA)

* Word frequency plots, word clouds
* Length distribution, class balance, and n-gram analysis

#### ğŸ§  Models Implemented

* **Traditional Machine Learning**:

  * Naive Bayes
  * Clustering (e.g., K-Means)
* **Deep Learning**:

  * LSTM
  * Transformer (e.g., using Hugging Face BERT or similar)

#### ğŸ”§ Model Tuning

* Hyperparameter optimisation
* Architecture modifications
* Early stopping, dropout, embedding layers (for deep models)

#### ğŸ“ˆ Evaluation Metrics

* F1 Score, Accuracy, Precision, Recall
* ROC-AUC / PR-AUC
* Confusion Matrix, classification reports

---

## ğŸ“Š Visual Outputs

* Model performance comparison plots
* Training/validation loss & accuracy curves
* Confusion matrices
* Word clouds and EDA charts
* Attention visualisations (if using transformers)

---

## ğŸ›  Technologies Used

* Python 3.x
* Jupyter Notebook
* Scikit-learn, TensorFlow, Keras
* NLTK, spaCy, Hugging Face Transformers
* Pandas, NumPy
* Matplotlib, Seaborn

---



