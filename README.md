ðŸ§  AI Coursework â€“ CNN Presentation & NLP Project
This repository includes two major components completed as part of my AI coursework:

A video presentation on Convolutional Neural Networks (CNNs), explaining the fundamentals, real-world applications, and ethical considerations.

A full Natural Language Processing (NLP) application and report, covering end-to-end data analysis, model comparison, evaluation, and interpretation using traditional and deep learning methods.

ðŸŽ¤ Part 1: CNN Presentation (30% of grade)
Objective:
Deliver a concise 5-minute presentation that introduces CNNs, explores a real-world research paper using CNNs, addresses ethical implications, and reflects on personal experience with CNNs in practical lab settings.

ðŸ“Œ Contents:
Definition & Working of CNNs:

Explanation of key components like convolution layers, activation functions, max pooling, dropout, and flattening.

Ethical Consideration:

A brief discussion of a real-world ethical issue (e.g., bias in facial recognition, surveillance, etc.) involving CNNs.

Academic Paper Analysis:

Chosen paper sourced from the university library.

Described the goals, motivation, and architecture used in the paper.

Explained why CNNs were the appropriate choice.

Visualisations:

Diagram of CNN architecture.

Visuals from the paper (e.g., confusion matrix, example image classification outputs).

Reflection:

A short commentary on my personal experience implementing CNNs during lab sessions (e.g., MNIST classification).


ðŸ“— Part 2: NLP Application and Report (70% of grade)
Objective:
Build and evaluate an NLP application using publicly available data. The task includes comparison of traditional ML models and deep learning models, complete with preprocessing, evaluation, and detailed reporting.

ðŸ“Œ Key Components:
Application Goal:

Chose an NLP use case (e.g., text classification, sentiment analysis, topic modelling, etc.) with societal or industry relevance.

Provided background on similar systems from research or industry use (via literature review).

SMART Objectives:

Defined specific, measurable, achievable, relevant, and time-bound goals based on research and dataset context.

Dataset:

Description of dataset structure, size, format, balance, and limitations.

Used preprocessing steps such as tokenisation, stopword removal, padding, and vectorisation.

Model Implementation:

Traditional ML: Naive Bayes, K-Means or similar clustering algorithm.

Deep Learning: LSTM, Transformer or standard RNN.

Model Tuning:

Applied techniques like grid search, learning rate tuning, number of hidden layers, dropout, batch size.

Evaluation:

Used metrics such as F1 Score, Accuracy, ROC-AUC, PR-AUC for performance assessment.

Compared model results visually and statistically to determine best performer.


ðŸ§ª Technologies Used
Python 3.x

Jupyter Notebook

TensorFlow / Keras

Scikit-learn

Pandas, NumPy, NLTK, spaCy

Matplotlib / Seaborn

Hugging Face Transformers (optional for BERT/Transformer model)

