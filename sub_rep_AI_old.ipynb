{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c556435-6ccb-44f1-b4d8-8bc540e9ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7686e0-80ee-4e2a-b668-7328deaf3320",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0dde22-1fd7-43f7-81bb-050c0a24f918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          statement   status\n",
       "0           0                                         oh my gosh  Anxiety\n",
       "1           1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2           2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3           3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4           4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Combined Data.csv/Combined Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b96b695-f9c4-447f-a3e7-6fd98a16fb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I've shifted my focus to something else but I'...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm restless and restless, it's been a month n...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement   status\n",
       "0                                         oh my gosh  Anxiety\n",
       "1  trouble sleeping, confused mind, restless hear...  Anxiety\n",
       "2  All wrong, back off dear, forward doubt. Stay ...  Anxiety\n",
       "3  I've shifted my focus to something else but I'...  Anxiety\n",
       "4  I'm restless and restless, it's been a month n...  Anxiety"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'Unnamed: 0' column\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Display the first few rows to verify\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb1b4ad-461b-4c95-b562-5f6278495fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53038</th>\n",
       "      <td>Nobody takes me seriously I’ve (24M) dealt wit...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53039</th>\n",
       "      <td>selfishness  \"I don't feel very good, it's lik...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53040</th>\n",
       "      <td>Is there any way to sleep better? I can't slee...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53041</th>\n",
       "      <td>Public speaking tips? Hi, all. I have to give ...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53042</th>\n",
       "      <td>I have really bad door anxiety! It's not about...</td>\n",
       "      <td>Anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               statement   status\n",
       "53038  Nobody takes me seriously I’ve (24M) dealt wit...  Anxiety\n",
       "53039  selfishness  \"I don't feel very good, it's lik...  Anxiety\n",
       "53040  Is there any way to sleep better? I can't slee...  Anxiety\n",
       "53041  Public speaking tips? Hi, all. I have to give ...  Anxiety\n",
       "53042  I have really bad door anxiety! It's not about...  Anxiety"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb4e68b-2b15-495c-8db2-2b1aac10560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53043 entries, 0 to 53042\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   statement  52681 non-null  object\n",
      " 1   status     53043 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 828.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3416e0ce-0ac5-4c27-b047-47ba96089e45",
   "metadata": {},
   "source": [
    "# Length of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c00b53be-5dca-4afb-bd5d-95ad5f70632d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53043"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6549424c-0a71-440a-864a-3af5acfe7430",
   "metadata": {},
   "source": [
    "# size and shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91ca9ef7-308c-442d-9b1c-27e8da6a13a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 53043\n",
      "Number of columns: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c2d799-bb1a-470c-a378-8cf88c3b8a80",
   "metadata": {},
   "source": [
    "# Description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee9c1ce-2b67-45c9-b1aa-5effcbfd7f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52681</td>\n",
       "      <td>53043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>51073</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>what do you mean?</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>22</td>\n",
       "      <td>16351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                statement  status\n",
       "count               52681   53043\n",
       "unique              51073       7\n",
       "top     what do you mean?  Normal\n",
       "freq                   22   16351"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7054a-0582-48fa-a5d1-cae541426074",
   "metadata": {},
   "source": [
    "# checking for missing values in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbf99c7-1c23-4ee8-be09-9f0f16380b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement    362\n",
      "status         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "059af349-e34f-4136-9e6f-c71c59137eac",
   "metadata": {},
   "source": [
    "This DataFrame have two columns: statement and status.\n",
    "\n",
    "statement column has 362 missing values (NaN).\n",
    "status column has no missing values (all values are present)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db8d155-64a9-4c42-88fa-a6f68a7276cd",
   "metadata": {},
   "source": [
    "# Dropping these missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f7d6a1-852c-4848-97ba-16f51f5bf8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statement    0\n",
      "status       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da90bdc3-ffae-490b-b3b1-b7a4b4d95daa",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82f8684d-65f4-4b43-9046-71c13d6a6852",
   "metadata": {},
   "source": [
    "Basic statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9834b608-0057-4b77-8b26-8a2141c94cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    52681.000000\n",
      "mean       578.713863\n",
      "std        846.269078\n",
      "min          2.000000\n",
      "25%         80.000000\n",
      "50%        317.000000\n",
      "75%        752.000000\n",
      "max      32759.000000\n",
      "Name: statement_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the length of each statement\n",
    "df['statement_length'] = df['statement'].apply(len)\n",
    "\n",
    "# Display basic statistics of statement lengths\n",
    "print(df['statement_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff23d014-23a4-4930-b9a5-a3c0483c0582",
   "metadata": {},
   "source": [
    "# checking the number of nunique values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c7e3168-eaa0-455b-a96d-8d3f3728baba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874d5b7-2c48-439a-bdcc-0981453a469a",
   "metadata": {},
   "source": [
    "# checking the unique values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f1828ba-7f5b-4d6a-824d-126969a91fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anxiety', 'Normal', 'Depression', 'Suicidal', 'Stress', 'Bipolar',\n",
       "       'Personality disorder'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1330a847-70df-4084-86e7-1ee78925c2a8",
   "metadata": {},
   "source": [
    "# number of characters and words per statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c0b9bf-8544-4539-925f-3999a696eaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum number of characters per statment: 32759\n",
      "maximum number of words per statment: 6300\n"
     ]
    }
   ],
   "source": [
    "# characters length\n",
    "df['statment_length']=df['statement'].apply(lambda x:len(x))\n",
    "# words length\n",
    "df['num_of_words']=df['statement'].apply(lambda x:len(x.split()))\n",
    "print(\"maximum number of characters per statment:\", df['statment_length'].max())\n",
    "print(\"maximum number of words per statment:\", df['num_of_words'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e5c30-da4a-4610-8a2e-dbd147964e12",
   "metadata": {},
   "source": [
    "# distribution of the 'status' column with their value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed8e41fe-23f7-4fa0-a0fa-eeb6d2d29a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "Normal                  16343\n",
      "Depression              15404\n",
      "Suicidal                10652\n",
      "Anxiety                  3841\n",
      "Bipolar                  2777\n",
      "Stress                   2587\n",
      "Personality disorder     1077\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the 'status' column with their value counts\n",
    "sentiment_distribution = df['status'].value_counts()\n",
    "\n",
    "# Display the distribution\n",
    "print(sentiment_distribution)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44745f6a-a496-48ea-8409-e1f431238242",
   "metadata": {},
   "source": [
    "As we can see that the dataset is not balanced because:\n",
    "The class \"Normal\" has 16,343 instances, while the class \"Personality disorder\" has only 1,077 instances.\n",
    "The other classes fall somewhere in between, with \"Depression\" having 15,404 instances and \"Anxiety\" having 3,841 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea1f3bf4-edb4-420c-b76b-43376445323e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Distribution of Sentiments'}, xlabel='status'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting graph for visualizations\n",
    "sentiment_distribution.plot(kind='bar', title='Distribution of Sentiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d9807-2cb1-41f2-97d2-fc71e3a38026",
   "metadata": {},
   "source": [
    "# Correlation between statment length and number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e288884e-1c5d-42f4-a69b-01ab06da27a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "corr=df[['statment_length','num_of_words']].corr()\n",
    "sns.heatmap(corr,annot=True,fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db2f4e-4ebe-4ce2-975e-7e25af1abbe5",
   "metadata": {},
   "source": [
    "# Data Preprocessing:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4eb992a3-cf59-4af1-9849-8f0358b546e2",
   "metadata": {},
   "source": [
    "# check for repetive words,stopwords and punctuation and convert words to lower\n",
    "Convert text to lowercase\n",
    "Remove punctuation\n",
    "Remove stopwords\n",
    "Remove repetitive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b3a3f4b-e1f2-4584-887b-f2abb1d6581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\masih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\masih\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import download\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "download('stopwords')\n",
    "download('punkt')\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Remove repetitive words (keep only unique words)\n",
    "    tokens = list(set(tokens))\n",
    "    \n",
    "    # Reconstruct the text from tokens\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3688ee1-4cde-4de4-bbc5-12b6d68239fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       cleaned_statement   status\n",
      "0                                                oh gosh  Anxiety\n",
      "1      restless heart tune mind confused trouble slee...  Anxiety\n",
      "2      doubt dear stay forward restless back place wrong  Anxiety\n",
      "3      ive still focus else something im worried shifted  Anxiety\n",
      "4                             mean restless boy im month  Anxiety\n",
      "...                                                  ...      ...\n",
      "53038  ended alone eventually normal feel vitamin lik...  Anxiety\n",
      "53039  try suffered deserve gt least mistake belong c...  Anxiety\n",
      "53040       way nights help better sleep meds cant didnt  Anxiety\n",
      "53041  speaking week ceo forget certain much kicks su...  Anxiety\n",
      "53042  bad honestly door pulling opening problem way ...  Anxiety\n",
      "\n",
      "[52681 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the 'statement' column\n",
    "df['cleaned_statement'] = df['statement'].apply(preprocess_text)\n",
    "\n",
    "# Display the DataFrame with cleaned text\n",
    "print(df[['cleaned_statement', 'status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2876700d-2a70-4a84-9dce-7035ef6a318b",
   "metadata": {},
   "source": [
    "# Balancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b508815d-4883-4b1b-a02d-f3438318a9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'Normal': 16343, 'Depression': 15404, 'Suicidal': 10652, 'Anxiety': 3841, 'Bipolar': 2777, 'Stress': 2587, 'Personality disorder': 1077})\n",
      "Resampled dataset shape: Counter({'Anxiety': 16343, 'Normal': 16343, 'Depression': 16343, 'Suicidal': 16343, 'Stress': 16343, 'Bipolar': 16343, 'Personality disorder': 16343})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = df['cleaned_statement']  # Use preprocessed text data\n",
    "y = df['status']  # Use the original status labels (categorical)\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
    "\n",
    "# Check the new class distribution\n",
    "print('Original dataset shape:', Counter(y))\n",
    "print('Resampled dataset shape:', Counter(y_resampled))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84601d-4cea-4305-a206-fa8647ca2f2a",
   "metadata": {},
   "source": [
    "# Training and Testing Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0143aa86-daea-44e4-90eb-06c82a1a2de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (91520, 78550)\n",
      "X_test shape: (22881, 78550)\n",
      "y_train shape: (91520,)\n",
      "y_test shape: (22881,)\n"
     ]
    }
   ],
   "source": [
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the train and test sets\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e5c1e-7500-468c-94d7-73cd25eb11de",
   "metadata": {},
   "source": [
    "# Traditional Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92063579-9d83-466f-92c2-17900fac67ee",
   "metadata": {},
   "source": [
    "# Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31eb3385-9e44-4b81-aaca-a7984e9ab49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.85      0.88      0.86      3375\n",
      "             Bipolar       0.78      0.96      0.86      3214\n",
      "          Depression       0.60      0.60      0.60      3274\n",
      "              Normal       0.96      0.42      0.58      3325\n",
      "Personality disorder       0.73      0.99      0.84      3241\n",
      "              Stress       0.80      0.84      0.82      3209\n",
      "            Suicidal       0.73      0.65      0.69      3243\n",
      "\n",
      "            accuracy                           0.76     22881\n",
      "           macro avg       0.78      0.76      0.75     22881\n",
      "        weighted avg       0.78      0.76      0.75     22881\n",
      "\n",
      "ROC-AUC: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Assuming X_resampled and y_resampled are already defined# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "y_prob = nb_clf.predict_proba(X_test)\n",
    "\n",
    "# Print the classification report for each classprint(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Binarize the output labels for ROC-AUC calculation (for multi-class problems)\n",
    "y_test_bin = label_binarize(y_test, classes=nb_clf.classes_)\n",
    "\n",
    "# Calculate the ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test_bin, y_prob, multi_class='ovr')\n",
    "\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804592be-c8fb-4b4f-ad56-133e819aa3a7",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbdc9d14-baee-44d3-8dbd-ec5612ec5dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.1, 'fit_prior': False}\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.87      0.93      0.90      3375\n",
      "             Bipolar       0.87      0.97      0.92      3214\n",
      "          Depression       0.69      0.59      0.63      3274\n",
      "              Normal       0.93      0.62      0.75      3325\n",
      "Personality disorder       0.86      0.99      0.92      3241\n",
      "              Stress       0.86      0.93      0.89      3209\n",
      "            Suicidal       0.71      0.78      0.75      3243\n",
      "\n",
      "            accuracy                           0.83     22881\n",
      "           macro avg       0.83      0.83      0.82     22881\n",
      "        weighted avg       0.83      0.83      0.82     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def tune_naive_bayes(X_resampled, y_resampled, param_grid, test_size=0.2, random_state=42, cv=5):\n",
    "    \"\"\"\n",
    "    Function to perform hyperparameter tuning on a Multinomial Naive Bayes model.\n",
    "\n",
    "    Parameters:\n",
    "    - X_resampled: Feature matrix (sparse matrix or dense array).\n",
    "    - y_resampled: Target vector.\n",
    "    - param_grid: Dictionary of hyperparameters to tune.\n",
    "    - test_size: Proportion of the dataset to include in the test split.\n",
    "    - random_state: Controls the shuffling applied to the data before applying the split.\n",
    "    - cv: Number of cross-validation folds.\n",
    "\n",
    "    Returns:\n",
    "    - best_params: Best hyperparameters found.\n",
    "    - metrics: Dictionary containing evaluation metrics (classification report and ROC-AUC).\n",
    "    \"\"\"# Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Initialize the Naive Bayes classifier\n",
    "    nb_clf = MultinomialNB()\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(nb_clf, param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best estimator and its parameters\n",
    "    best_nb_clf = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the best estimator on the entire training set\n",
    "    best_nb_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = best_nb_clf.predict(X_test)\n",
    "    y_prob = best_nb_clf.predict_proba(X_test)\n",
    "\n",
    "    # Print the classification report\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Binarize the output labels for ROC-AUC calculation (for multi-class problems)\n",
    "    y_test_bin = label_binarize(y_test, classes=best_nb_clf.classes_)\n",
    "\n",
    "    # Calculate the ROC-AUC score\n",
    "    roc_auc = roc_auc_score(y_test_bin, y_prob, multi_class='ovr')\n",
    "\n",
    "    # Compile metrics\n",
    "    metrics = {\n",
    "        'classification_report': classification_rep,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "\n",
    "    return best_params, metrics\n",
    "\n",
    "# Example usage:\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0], 'fit_prior': [True, False]}\n",
    "best_params, metrics = tune_naive_bayes(X_resampled, y_resampled, param_grid)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Classification Report:\")\n",
    "print(metrics['classification_report'])\n",
    "print(f\"ROC-AUC: {metrics['ROC-AUC']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17e81261-01a0-423a-91a3-f45a70bbc83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.1, 'fit_prior': True}\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.88      0.92      0.90      3375\n",
      "             Bipolar       0.87      0.97      0.92      3214\n",
      "          Depression       0.69      0.58      0.63      3274\n",
      "              Normal       0.93      0.62      0.75      3325\n",
      "Personality disorder       0.86      0.99      0.92      3241\n",
      "              Stress       0.85      0.93      0.89      3209\n",
      "            Suicidal       0.71      0.78      0.75      3243\n",
      "\n",
      "            accuracy                           0.83     22881\n",
      "           macro avg       0.83      0.83      0.82     22881\n",
      "        weighted avg       0.83      0.83      0.82     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0, 5.0], 'fit_prior': [True]}\n",
    "best_params, metrics = tune_naive_bayes(X_resampled, y_resampled, param_grid)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Classification Report:\")\n",
    "print(metrics['classification_report'])\n",
    "print(f\"ROC-AUC: {metrics['ROC-AUC']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e82c3dbd-b0ee-475a-8be4-bea6724f9823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.01, 'fit_prior': False}\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.89      0.94      0.91      3375\n",
      "             Bipolar       0.88      0.98      0.93      3214\n",
      "          Depression       0.71      0.60      0.65      3274\n",
      "              Normal       0.94      0.64      0.76      3325\n",
      "Personality disorder       0.89      0.99      0.94      3241\n",
      "              Stress       0.88      0.94      0.91      3209\n",
      "            Suicidal       0.71      0.80      0.75      3243\n",
      "\n",
      "            accuracy                           0.84     22881\n",
      "           macro avg       0.84      0.84      0.84     22881\n",
      "        weighted avg       0.84      0.84      0.84     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "param_grid = {'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0], 'fit_prior': [True, False]}\n",
    "best_params, metrics = tune_naive_bayes(X_resampled, y_resampled, param_grid)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Classification Report:\")\n",
    "print(metrics['classification_report'])\n",
    "print(f\"ROC-AUC: {metrics['ROC-AUC']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92ab194a-e43e-4f41-b5df-4d899f436c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.01, 'fit_prior': True}\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.89      0.94      0.92      3375\n",
      "             Bipolar       0.88      0.98      0.93      3214\n",
      "          Depression       0.71      0.60      0.65      3274\n",
      "              Normal       0.94      0.64      0.76      3325\n",
      "Personality disorder       0.89      0.99      0.94      3241\n",
      "              Stress       0.88      0.94      0.91      3209\n",
      "            Suicidal       0.71      0.80      0.75      3243\n",
      "\n",
      "            accuracy                           0.84     22881\n",
      "           macro avg       0.84      0.84      0.84     22881\n",
      "        weighted avg       0.84      0.84      0.84     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "param_grid = {'alpha': [0.01, 0.05, 0.1, 0.5, 1.0], 'fit_prior': [True]}\n",
    "best_params, metrics = tune_naive_bayes(X_resampled, y_resampled, param_grid)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Classification Report:\")\n",
    "print(metrics['classification_report'])\n",
    "print(f\"ROC-AUC: {metrics['ROC-AUC']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8fcd9-a11a-40c3-ae5e-afdd3e1fb769",
   "metadata": {},
   "source": [
    "# Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df7c5aea-1de4-4316-b93c-ab573fc8a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.95      0.95      0.95      3375\n",
      "             Bipolar       0.96      0.96      0.96      3214\n",
      "          Depression       0.75      0.65      0.69      3274\n",
      "              Normal       0.85      0.91      0.88      3325\n",
      "Personality disorder       0.97      0.99      0.98      3241\n",
      "              Stress       0.91      0.95      0.93      3209\n",
      "            Suicidal       0.74      0.74      0.74      3243\n",
      "\n",
      "            accuracy                           0.88     22881\n",
      "           macro avg       0.88      0.88      0.88     22881\n",
      "        weighted avg       0.88      0.88      0.88     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "logreg_clf = LogisticRegression(max_iter=500, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "logreg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_clf.predict(X_test)\n",
    "y_prob = logreg_clf.predict_proba(X_test)\n",
    "\n",
    "# Print classification report for each label\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# For ROC-AUC, binarize the output labels if it's a multi-class problem\n",
    "y_test_bin = label_binarize(y_test, classes=logreg_clf.classes_)\n",
    "roc_auc = roc_auc_score(y_test_bin, y_prob, multi_class='ovr')\n",
    "\n",
    "# Print the ROC-AUC score\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b376bb28-e91e-4437-9a41-d4f31e94e9ca",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "742bd604-b1ee-466b-ae28-235980e95554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Classification Report:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.93      0.94      0.94      3375\n",
      "             Bipolar       0.96      0.96      0.96      3214\n",
      "          Depression       0.75      0.62      0.68      3274\n",
      "              Normal       0.84      0.92      0.87      3325\n",
      "Personality disorder       0.96      0.99      0.98      3241\n",
      "              Stress       0.90      0.93      0.92      3209\n",
      "            Suicidal       0.74      0.74      0.74      3243\n",
      "\n",
      "            accuracy                           0.87     22881\n",
      "           macro avg       0.87      0.87      0.87     22881\n",
      "        weighted avg       0.87      0.87      0.87     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Function to train and evaluate the Logistic Regression model\n",
    "def train_and_evaluate(X_resampled, y_resampled, param_grid=None):\n",
    "    # Split the resampled data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize the Logistic Regression classifier\n",
    "    logreg_clf = LogisticRegression(random_state=42)\n",
    "    \n",
    "    # If param_grid is provided, use GridSearchCV for hyperparameter tuning\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(logreg_clf, param_grid, scoring='accuracy', cv=3, n_jobs=-1)  \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        logreg_clf = grid_search.best_estimator_\n",
    "        print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    else:\n",
    "        # Train the classifier without hyperparameter tuning\n",
    "        logreg_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = logreg_clf.predict(X_test)\n",
    "    y_prob = logreg_clf.predict_proba(X_test)\n",
    "    \n",
    "    # Print classification report for each label\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # For ROC-AUC, binarize the output labels if it's a multi-class problem\n",
    "    y_test_bin = label_binarize(y_test, classes=logreg_clf.classes_)\n",
    "    roc_auc = roc_auc_score(y_test_bin, y_prob, multi_class='ovr')\n",
    "    \n",
    "    # Print the ROC-AUC score\n",
    "    print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Define the simplified parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0],\n",
    "    'solver': ['liblinear'],  # Use a single solver to speed up the process\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': [100]  # Fixed max_iter to avoid long runs\n",
    "}\n",
    "\n",
    "# Call the function with the simplified parameter grid for hyperparameter tuning\n",
    "train_and_evaluate(X_resampled, y_resampled, param_grid=param_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "caa14cc6-3024-40c7-84fb-8759818f7fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 5.0, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Classification Report:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.96      0.98      0.97      3375\n",
      "             Bipolar       0.97      0.98      0.98      3214\n",
      "          Depression       0.77      0.65      0.71      3274\n",
      "              Normal       0.89      0.92      0.90      3325\n",
      "Personality disorder       0.98      1.00      0.99      3241\n",
      "              Stress       0.93      0.98      0.95      3209\n",
      "            Suicidal       0.75      0.76      0.75      3243\n",
      "\n",
      "            accuracy                           0.89     22881\n",
      "           macro avg       0.89      0.89      0.89     22881\n",
      "        weighted avg       0.89      0.89      0.89     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Define the simplified parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.5, 1.0, 5.0],\n",
    "    'solver': ['liblinear'],  # Use a single solver to speed up the process\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': [150]  # Fixed max_iter to avoid long runs\n",
    "}\n",
    "\n",
    "# Call the function with the simplified parameter grid for hyperparameter tuning\n",
    "train_and_evaluate(X_resampled, y_resampled, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fd8b69b-d07a-47ae-b3f9-1493b5bf47c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Classification Report:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.96      0.98      0.97      3375\n",
      "             Bipolar       0.97      0.99      0.98      3214\n",
      "          Depression       0.78      0.67      0.72      3274\n",
      "              Normal       0.90      0.91      0.90      3325\n",
      "Personality disorder       0.98      1.00      0.99      3241\n",
      "              Stress       0.94      0.99      0.96      3209\n",
      "            Suicidal       0.75      0.77      0.76      3243\n",
      "\n",
      "            accuracy                           0.90     22881\n",
      "           macro avg       0.90      0.90      0.90     22881\n",
      "        weighted avg       0.90      0.90      0.90     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Define the simplified parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [1.0, 10.0],\n",
    "    'solver': ['liblinear'],  # Use a single solver to speed up the process\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': [100, 200]  # Fixed max_iter to avoid long runs\n",
    "}\n",
    "\n",
    "# Call the function with the simplified parameter grid for hyperparameter tuning\n",
    "train_and_evaluate(X_resampled, y_resampled, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e70fb7d0-ae7f-4027-894e-213dc7b146d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10.0, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Classification Report:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Anxiety       0.96      0.98      0.97      3375\n",
      "             Bipolar       0.97      0.99      0.98      3214\n",
      "          Depression       0.78      0.67      0.72      3274\n",
      "              Normal       0.90      0.91      0.90      3325\n",
      "Personality disorder       0.98      1.00      0.99      3241\n",
      "              Stress       0.94      0.99      0.96      3209\n",
      "            Suicidal       0.75      0.77      0.76      3243\n",
      "\n",
      "            accuracy                           0.90     22881\n",
      "           macro avg       0.90      0.90      0.90     22881\n",
      "        weighted avg       0.90      0.90      0.90     22881\n",
      "\n",
      "ROC-AUC: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Define the simplified parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [1.0, 10.0],\n",
    "    'solver': ['liblinear'],  # Use a single solver to speed up the process\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': [500]  # Fixed max_iter to avoid long runs\n",
    "}\n",
    "\n",
    "# Call the function with the simplified parameter grid for hyperparameter tuning\n",
    "train_and_evaluate(X_resampled, y_resampled, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11dbde4-fee7-497a-9892-6704e2d09a99",
   "metadata": {},
   "source": [
    "# Traditional Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c364e-98fc-4fae-ad1f-683ce5412612",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26c01dc6-4f65-4ae1-86ef-32c23f6f531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'Normal': 16343, 'Depression': 15404, 'Suicidal': 10652, 'Anxiety': 3841, 'Bipolar': 2777, 'Stress': 2587, 'Personality disorder': 1077})\n",
      "Resampled dataset shape: {0: 16343, 1: 16343, 2: 16343, 3: 16343, 4: 16343, 5: 16343, 6: 16343}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df['cleaned_statement'] and df['status'] are already defined and preprocessed\n",
    "X = df['cleaned_statement']  # Use preprocessed text data\n",
    "y = df['status']  # Use the original status labels (categorical)\n",
    "\n",
    "# Tokenize the text data\n",
    "vocab_size = 2000  # Reduce vocabulary size\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "max_len = 100  # Set a fixed sequence length\n",
    "X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
    "\n",
    "# Convert labels to numeric (one-hot encode)\n",
    "y_numeric = pd.get_dummies(y).values\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_pad, y_numeric)\n",
    "\n",
    "# Check the new class distribution, sorted by label\n",
    "resampled_counter = Counter(y_resampled.argmax(axis=1))\n",
    "sorted_resampled_counter = dict(sorted(resampled_counter.items()))\n",
    "\n",
    "print('Original dataset shape:', Counter(y))\n",
    "print('Resampled dataset shape:', sorted_resampled_counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54a9d08e-5b77-41b6-a313-3b666b9f0ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1430/1430 - 131s - 91ms/step - accuracy: 0.4451 - loss: 1.3555 - val_accuracy: 0.5050 - val_loss: 1.2120\n",
      "Epoch 2/5\n",
      "1430/1430 - 118s - 83ms/step - accuracy: 0.5303 - loss: 1.1515 - val_accuracy: 0.5240 - val_loss: 1.1578\n",
      "Epoch 3/5\n",
      "1430/1430 - 119s - 83ms/step - accuracy: 0.5565 - loss: 1.0868 - val_accuracy: 0.5356 - val_loss: 1.1414\n",
      "Epoch 4/5\n",
      "1430/1430 - 119s - 83ms/step - accuracy: 0.5755 - loss: 1.0456 - val_accuracy: 0.5345 - val_loss: 1.1377\n",
      "Epoch 5/5\n",
      "1430/1430 - 151s - 106ms/step - accuracy: 0.5903 - loss: 1.0089 - val_accuracy: 0.5437 - val_loss: 1.1248\n",
      "Test Accuracy: 0.54\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.33      0.41      3375\n",
      "           1       0.40      0.37      0.39      3214\n",
      "           2       0.71      0.67      0.69      3274\n",
      "           3       0.83      0.92      0.88      3325\n",
      "           4       0.38      0.48      0.42      3241\n",
      "           5       0.40      0.56      0.47      3209\n",
      "           6       0.61      0.47      0.53      3243\n",
      "\n",
      "    accuracy                           0.54     22881\n",
      "   macro avg       0.56      0.54      0.54     22881\n",
      "weighted avg       0.56      0.54      0.54     22881\n",
      "\n",
      "ROC-AUC: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the simplified LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=64))  # Embedding layer\n",
    "model.add(LSTM(64, return_sequences=False))  # LSTM layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class, y_pred))\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea08b81-7dfb-4b84-a3da-687137e0a853",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b843501-c643-4e4a-b21b-ac44ed13e5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'Normal': 16343, 'Depression': 15404, 'Suicidal': 10652, 'Anxiety': 3841, 'Bipolar': 2777, 'Stress': 2587, 'Personality disorder': 1077})\n",
      "Resampled dataset shape: {0: 16343, 1: 16343, 2: 16343, 3: 16343, 4: 16343, 5: 16343, 6: 16343}\n",
      "Epoch 1/5\n",
      "1430/1430 - 131s - 92ms/step - accuracy: 0.4444 - loss: 1.3592 - val_accuracy: 0.4950 - val_loss: 1.2380\n",
      "Epoch 2/5\n",
      "1430/1430 - 144s - 101ms/step - accuracy: 0.5309 - loss: 1.1539 - val_accuracy: 0.5276 - val_loss: 1.1482\n",
      "Epoch 3/5\n",
      "1430/1430 - 145s - 101ms/step - accuracy: 0.5537 - loss: 1.0933 - val_accuracy: 0.5344 - val_loss: 1.1266\n",
      "Epoch 4/5\n",
      "1430/1430 - 134s - 94ms/step - accuracy: 0.5694 - loss: 1.0562 - val_accuracy: 0.5393 - val_loss: 1.1270\n",
      "Epoch 5/5\n",
      "1430/1430 - 127s - 89ms/step - accuracy: 0.5826 - loss: 1.0227 - val_accuracy: 0.5408 - val_loss: 1.1217\n",
      "Test Accuracy: 0.54\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.32      0.40      3375\n",
      "           1       0.55      0.24      0.34      3214\n",
      "           2       0.69      0.68      0.69      3274\n",
      "           3       0.85      0.90      0.88      3325\n",
      "           4       0.34      0.57      0.43      3241\n",
      "           5       0.40      0.62      0.48      3209\n",
      "           6       0.61      0.46      0.52      3243\n",
      "\n",
      "    accuracy                           0.54     22881\n",
      "   macro avg       0.57      0.54      0.53     22881\n",
      "weighted avg       0.57      0.54      0.53     22881\n",
      "\n",
      "ROC-AUC: 0.87\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df['cleaned_statement'] and df['status'] are already defined and preprocessed\n",
    "X = df['cleaned_statement']  # Use preprocessed text data\n",
    "y = df['status']  # Use the original status labels (categorical)\n",
    "\n",
    "def preprocess_data(vocab_size=2000, max_len=100):\n",
    "    # Tokenize the text data\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "    # Pad sequences to ensure uniform input size\n",
    "    X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
    "\n",
    "    # Convert labels to numeric (one-hot encode)\n",
    "    y_numeric = pd.get_dummies(y).values\n",
    "\n",
    "    return X_pad, y_numeric, tokenizer\n",
    "\n",
    "def oversample_data(X_pad, y_numeric, random_state=42):\n",
    "    # Apply SMOTE to balance the dataset\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=random_state)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_pad, y_numeric)\n",
    "\n",
    "    # Check the new class distribution, sorted by label\n",
    "    resampled_counter = Counter(y_resampled.argmax(axis=1))\n",
    "    sorted_resampled_counter = dict(sorted(resampled_counter.items()))\n",
    "\n",
    "    print('Original dataset shape:', Counter(y))\n",
    "    print('Resampled dataset shape:', sorted_resampled_counter)\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def build_model(vocab_size, output_dim=64, lstm_units=64, dense_units=32):\n",
    "    # Build the simplified LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=output_dim))  # Embedding layer\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))  # LSTM layer\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=5, batch_size=64, verbose=2):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=verbose)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Evaluate the model on the test data\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "\n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_class, y_pred))\n",
    "\n",
    "    # Calculate ROC-AUC score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
    "    print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "\n",
    "# Preprocess data\n",
    "X_pad, y_numeric, tokenizer = preprocess_data(vocab_size=2000, max_len=100)\n",
    "\n",
    "# Oversample data\n",
    "X_resampled, y_resampled = oversample_data(X_pad, y_numeric, random_state=42)\n",
    "\n",
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = build_model(vocab_size=2000, output_dim=64, lstm_units=64, dense_units=32)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, X_train, y_train, X_test, y_test, epochs=5, batch_size=64, verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec923f38-2f7c-4086-a133-de6fb69814a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1430/1430 - 129s - 90ms/step - accuracy: 0.4310 - loss: 1.3831 - val_accuracy: 0.4967 - val_loss: 1.2293\n",
      "Epoch 2/5\n",
      "1430/1430 - 126s - 88ms/step - accuracy: 0.5192 - loss: 1.1828 - val_accuracy: 0.5298 - val_loss: 1.1488\n",
      "Epoch 3/5\n",
      "1430/1430 - 143s - 100ms/step - accuracy: 0.5473 - loss: 1.1127 - val_accuracy: 0.5344 - val_loss: 1.1298\n",
      "Epoch 4/5\n",
      "1430/1430 - 130s - 91ms/step - accuracy: 0.5625 - loss: 1.0754 - val_accuracy: 0.5420 - val_loss: 1.1188\n",
      "Epoch 5/5\n",
      "1430/1430 - 126s - 88ms/step - accuracy: 0.5727 - loss: 1.0488 - val_accuracy: 0.5439 - val_loss: 1.1194\n",
      "Test Accuracy: 0.54\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.31      0.41      3375\n",
      "           1       0.44      0.35      0.39      3214\n",
      "           2       0.68      0.69      0.69      3274\n",
      "           3       0.85      0.91      0.88      3325\n",
      "           4       0.35      0.52      0.42      3241\n",
      "           5       0.40      0.58      0.47      3209\n",
      "           6       0.63      0.44      0.52      3243\n",
      "\n",
      "    accuracy                           0.54     22881\n",
      "   macro avg       0.57      0.54      0.54     22881\n",
      "weighted avg       0.57      0.54      0.54     22881\n",
      "\n",
      "ROC-AUC: 0.87\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_data(df, vocab_size=2000, max_len=100):\n",
    "    \"\"\"\n",
    "    Tokenizes and pads the text data, applies SMOTE, and splits the data into training and test sets.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame containing 'cleaned_statement' and 'status'.\n",
    "    - vocab_size: Number of words to keep in the tokenizer.\n",
    "    - max_len: Maximum length of sequences for padding.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test: Split and resampled data.\n",
    "    \"\"\"\n",
    "    X = df['cleaned_statement']\n",
    "    y = df['status']\n",
    "    \n",
    "    # Tokenize the text data\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    X_seq = tokenizer.texts_to_sequences(X)\n",
    "    \n",
    "    # Pad sequences to ensure uniform input size\n",
    "    X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
    "    \n",
    "    # Convert labels to numeric (one-hot encode)\n",
    "    y_numeric = pd.get_dummies(y).values\n",
    "    \n",
    "    # Apply SMOTE to balance the dataset\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_pad, y_numeric)\n",
    "    \n",
    "    # Split the resampled data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, tokenizer\n",
    "\n",
    "def build_and_train_lstm(X_train, y_train, X_test, y_test, vocab_size=2000, embedding_dim=64, lstm_units=64, dropout_rate=0.2, epochs=5, batch_size=64):\n",
    "    \"\"\"\n",
    "    Builds, compiles, and trains an LSTM model with specified hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "    - X_train, y_train: Training data.\n",
    "    - X_test, y_test: Test data.\n",
    "    - vocab_size: Size of the vocabulary.\n",
    "    - embedding_dim: Dimension of the embedding layer.\n",
    "    - lstm_units: Number of units in the LSTM layer.\n",
    "    - dropout_rate: Dropout rate.\n",
    "    - epochs: Number of training epochs.\n",
    "    - batch_size: Batch size for training.\n",
    "    \n",
    "    Returns:\n",
    "    - model: Trained Keras model.\n",
    "    \"\"\"\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model and prints performance metrics.\n",
    "    \n",
    "    Args:\n",
    "    - model: Trained Keras model.\n",
    "    - X_test, y_test: Test data.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test Accuracy: {accuracy:.2f}')\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    \n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_test_class = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_class, y_pred))\n",
    "    \n",
    "    # Calculate ROC-AUC score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
    "    print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    #df = pd.read_csv('Combined Data.csv/Combined Data.csv')\n",
    "    #df = df.drop(columns=['Unnamed: 0'])\n",
    "    #df = df.dropna()\n",
    "    \n",
    "    # Hyperparameters\n",
    "    vocab_size = 2000\n",
    "    max_len = 100\n",
    "    embedding_dim = 64\n",
    "    lstm_units = 64\n",
    "    dropout_rate = 0.2\n",
    "    epochs = 5\n",
    "    batch_size = 64\n",
    "    \n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test, tokenizer = preprocess_data(df, vocab_size, max_len)\n",
    "    \n",
    "    # Build and train the model\n",
    "    model = build_and_train_lstm(X_train, y_train, X_test, y_test, vocab_size, embedding_dim, lstm_units, dropout_rate, epochs, batch_size)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a07cf75a-0932-453e-967e-895d2a671dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1430/1430 - 133s - 93ms/step - accuracy: 0.4338 - loss: 1.3815 - val_accuracy: 0.4966 - val_loss: 1.2280\n",
      "Epoch 2/5\n",
      "1430/1430 - 131s - 92ms/step - accuracy: 0.5198 - loss: 1.1847 - val_accuracy: 0.5207 - val_loss: 1.1674\n",
      "Epoch 3/5\n",
      "1430/1430 - 138s - 96ms/step - accuracy: 0.5467 - loss: 1.1184 - val_accuracy: 0.5289 - val_loss: 1.1501\n",
      "Epoch 4/5\n",
      "1430/1430 - 146s - 102ms/step - accuracy: 0.5629 - loss: 1.0798 - val_accuracy: 0.5374 - val_loss: 1.1215\n",
      "Epoch 5/5\n",
      "1430/1430 - 145s - 101ms/step - accuracy: 0.5721 - loss: 1.0501 - val_accuracy: 0.5417 - val_loss: 1.1221\n",
      "Test Accuracy: 0.54\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.31      0.41      3375\n",
      "           1       0.43      0.37      0.40      3214\n",
      "           2       0.72      0.66      0.69      3274\n",
      "           3       0.84      0.91      0.88      3325\n",
      "           4       0.36      0.45      0.40      3241\n",
      "           5       0.38      0.63      0.48      3209\n",
      "           6       0.62      0.46      0.53      3243\n",
      "\n",
      "    accuracy                           0.54     22881\n",
      "   macro avg       0.56      0.54      0.54     22881\n",
      "weighted avg       0.57      0.54      0.54     22881\n",
      "\n",
      "ROC-AUC: 0.87\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_data(df, vocab_size, max_len):\n",
    "    \"\"\"\n",
    "    Tokenizes and pads the text data, applies SMOTE, and splits the data into training and test sets.\n",
    "    \n",
    "    Args:\n",
    "    - df: DataFrame containing 'cleaned_statement' and 'status'.\n",
    "    - vocab_size: Number of words to keep in the tokenizer.\n",
    "    - max_len: Maximum length of sequences for padding.\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, X_test, y_train, y_test: Split and resampled data.\n",
    "    \"\"\"\n",
    "    X = df['cleaned_statement']\n",
    "    y = df['status']\n",
    "    \n",
    "    # Tokenize the text data\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    X_seq = tokenizer.texts_to_sequences(X)\n",
    "    \n",
    "    # Pad sequences to ensure uniform input size\n",
    "    X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
    "    \n",
    "    # Convert labels to numeric (one-hot encode)\n",
    "    y_numeric = pd.get_dummies(y).values\n",
    "    \n",
    "    # Apply SMOTE to balance the dataset\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_pad, y_numeric)\n",
    "    \n",
    "    # Split the resampled data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, tokenizer\n",
    "\n",
    "def build_and_train_lstm(X_train, y_train, X_test, y_test, vocab_size, embedding_dim, lstm_units, dropout_rate, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Builds, compiles, and trains an LSTM model with specified hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "    - X_train, y_train: Training data.\n",
    "    - X_test, y_test: Test data.\n",
    "    - vocab_size: Size of the vocabulary.\n",
    "    - embedding_dim: Dimension of the embedding layer.\n",
    "    - lstm_units: Number of units in the LSTM layer.\n",
    "    - dropout_rate: Dropout rate.\n",
    "    - epochs: Number of training epochs.\n",
    "    - batch_size: Batch size for training.\n",
    "    \n",
    "    Returns:\n",
    "    - model: Trained Keras model.\n",
    "    \"\"\"\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "    model.add(LSTM(lstm_units, return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=2)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the model and prints performance metrics.\n",
    "    \n",
    "    Args:\n",
    "    - model: Trained Keras model.\n",
    "    - X_test, y_test: Test data.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test Accuracy: {accuracy:.2f}')\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    \n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_test_class = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_class, y_pred))\n",
    "    \n",
    "    # Calculate ROC-AUC score\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
    "    print(f'ROC-AUC: {roc_auc:.2f}')\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    #df = pd.read_csv('Combined Data.csv/Combined Data.csv')\n",
    "    #df = df.drop(columns=['Unnamed: 0'])\n",
    "    #df = df.dropna()\n",
    "    \n",
    "    # Hyperparameters\n",
    "    vocab_size = 2000\n",
    "    max_len = 150\n",
    "    embedding_dim = 64\n",
    "    lstm_units = 64\n",
    "    dropout_rate = 0.2\n",
    "    epochs = 5\n",
    "    batch_size = 64\n",
    "    \n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test, tokenizer = preprocess_data(df, vocab_size, max_len)\n",
    "    \n",
    "    # Build and train the model\n",
    "    model = build_and_train_lstm(X_train, y_train, X_test, y_test, vocab_size, embedding_dim, lstm_units, dropout_rate, epochs, batch_size)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a024d63-50e2-4eba-93d4-d3f5f2d11d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1430/1430 - 196s - 137ms/step - accuracy: 0.4351 - loss: 1.3775 - val_accuracy: 0.4921 - val_loss: 1.2313\n",
      "Epoch 2/5\n",
      "1430/1430 - 199s - 139ms/step - accuracy: 0.5214 - loss: 1.1756 - val_accuracy: 0.5305 - val_loss: 1.1494\n",
      "Epoch 3/5\n",
      "1430/1430 - 211s - 147ms/step - accuracy: 0.5484 - loss: 1.1140 - val_accuracy: 0.5333 - val_loss: 1.1303\n",
      "Epoch 4/5\n",
      "1430/1430 - 194s - 136ms/step - accuracy: 0.5619 - loss: 1.0753 - val_accuracy: 0.5390 - val_loss: 1.1270\n",
      "Epoch 5/5\n",
      "1430/1430 - 199s - 139ms/step - accuracy: 0.5715 - loss: 1.0490 - val_accuracy: 0.5452 - val_loss: 1.1220\n",
      "Test Accuracy: 0.55\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 38ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.31      0.41      3375\n",
      "           1       0.43      0.37      0.40      3214\n",
      "           2       0.69      0.71      0.70      3274\n",
      "           3       0.86      0.89      0.88      3325\n",
      "           4       0.36      0.50      0.42      3241\n",
      "           5       0.40      0.61      0.49      3209\n",
      "           6       0.60      0.42      0.50      3243\n",
      "\n",
      "    accuracy                           0.55     22881\n",
      "   macro avg       0.57      0.54      0.54     22881\n",
      "weighted avg       0.57      0.55      0.54     22881\n",
      "\n",
      "ROC-AUC: 0.87\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    #df = pd.read_csv('Combined Data.csv/Combined Data.csv')\n",
    "    #df = df.drop(columns=['Unnamed: 0'])\n",
    "    #df = df.dropna()\n",
    "    \n",
    "    # Hyperparameters\n",
    "    vocab_size = 2000\n",
    "    max_len = 150\n",
    "    embedding_dim = 64\n",
    "    lstm_units = 64\n",
    "    dropout_rate = 0.2\n",
    "    epochs = 5\n",
    "    batch_size = 64\n",
    "    \n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test, tokenizer = preprocess_data(df, vocab_size, max_len)\n",
    "    \n",
    "    # Build and train the model\n",
    "    model = build_and_train_lstm(X_train, y_train, X_test, y_test, vocab_size, embedding_dim, lstm_units, dropout_rate, epochs, batch_size)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1161134a-eec5-4899-9d62-68333d1043a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2860/2860 - 748s - 261ms/step - accuracy: 0.4543 - loss: 1.3359 - val_accuracy: 0.5090 - val_loss: 1.1909\n",
      "Epoch 2/5\n",
      "2860/2860 - 1002s - 350ms/step - accuracy: 0.5296 - loss: 1.1520 - val_accuracy: 0.5357 - val_loss: 1.1249\n",
      "Epoch 3/5\n",
      "2860/2860 - 738s - 258ms/step - accuracy: 0.5546 - loss: 1.0867 - val_accuracy: 0.5409 - val_loss: 1.1020\n",
      "Epoch 4/5\n",
      "2860/2860 - 736s - 257ms/step - accuracy: 0.5712 - loss: 1.0431 - val_accuracy: 0.5438 - val_loss: 1.1064\n",
      "Epoch 5/5\n",
      "2860/2860 - 737s - 258ms/step - accuracy: 0.5885 - loss: 1.0057 - val_accuracy: 0.5484 - val_loss: 1.0913\n",
      "Test Accuracy: 0.55\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 95ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.38      0.43      3375\n",
      "           1       0.42      0.38      0.40      3214\n",
      "           2       0.74      0.65      0.69      3274\n",
      "           3       0.84      0.92      0.88      3325\n",
      "           4       0.38      0.47      0.42      3241\n",
      "           5       0.42      0.55      0.48      3209\n",
      "           6       0.59      0.49      0.53      3243\n",
      "\n",
      "    accuracy                           0.55     22881\n",
      "   macro avg       0.56      0.55      0.55     22881\n",
      "weighted avg       0.56      0.55      0.55     22881\n",
      "\n",
      "ROC-AUC: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    #df = pd.read_csv('Combined Data.csv/Combined Data.csv')\n",
    "    #df = df.drop(columns=['Unnamed: 0'])\n",
    "    #df = df.dropna()\n",
    "    \n",
    "    # Hyperparameters\n",
    "    vocab_size = 2000\n",
    "    max_len = 300\n",
    "    embedding_dim = 128\n",
    "    lstm_units = 128\n",
    "    dropout_rate = 0.3\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    \n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test, tokenizer = preprocess_data(df, vocab_size, max_len)\n",
    "    \n",
    "    # Build and train the model\n",
    "    model = build_and_train_lstm(X_train, y_train, X_test, y_test, vocab_size, embedding_dim, lstm_units, dropout_rate, epochs, batch_size)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff85fa-fe5b-4fcf-88b8-2effb8ff4386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    vocab_size = 5000\n",
    "    max_len = 400\n",
    "    embedding_dim = 200\n",
    "    lstm_units = 256\n",
    "    dropout_rate = 0.2\n",
    "    epochs = 10\n",
    "    batch_size = 64# Preprocess data\n",
    "    X_train, X_test, y_train, y_test, tokenizer = preprocess_data(df, vocab_size, max_len)\n",
    "    \n",
    "    # Build and train the model\n",
    "    model = build_and_train_lstm(X_train, y_train, X_test, y_test, vocab_size, embedding_dim, lstm_units, dropout_rate, epochs, batch_size)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18ff71-9f81-4c4b-84df-257c1487ed9b",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa19a208-04f4-4278-b242-a4761c8b7c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({'Normal': 16343, 'Depression': 15404, 'Suicidal': 10652, 'Anxiety': 3841, 'Bipolar': 2777, 'Stress': 2587, 'Personality disorder': 1077})\n",
      "Resampled dataset shape: {0: 16343, 1: 16343, 2: 16343, 3: 16343, 4: 16343, 5: 16343, 6: 16343}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df['cleaned_statement'] and df['status'] are already defined and preprocessed\n",
    "X = df['cleaned_statement']  # Use preprocessed text data\n",
    "y = df['status']  # Use the original status labels (categorical)\n",
    "\n",
    "# Tokenize the text data\n",
    "vocab_size = 2000  # Reduce vocabulary size\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "max_len = 100  # Set a fixed sequence length\n",
    "X_pad = pad_sequences(X_seq, maxlen=max_len)\n",
    "\n",
    "# Convert labels to numeric (one-hot encode)\n",
    "y_numeric = pd.get_dummies(y).values\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_pad, y_numeric)\n",
    "\n",
    "# Check the new class distribution, sorted by label\n",
    "resampled_counter = Counter(y_resampled.argmax(axis=1))\n",
    "sorted_resampled_counter = dict(sorted(resampled_counter.items()))\n",
    "\n",
    "print('Original dataset shape:', Counter(y))\n",
    "print('Resampled dataset shape:', sorted_resampled_counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc755813-f812-4056-9a61-203e1c0994a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1430/1430 - 56s - 39ms/step - accuracy: 0.4287 - loss: 1.4037 - val_accuracy: 0.5001 - val_loss: 1.2314\n",
      "Epoch 2/5\n",
      "1430/1430 - 81s - 57ms/step - accuracy: 0.5255 - loss: 1.1843 - val_accuracy: 0.5309 - val_loss: 1.1626\n",
      "Epoch 3/5\n",
      "1430/1430 - 80s - 56ms/step - accuracy: 0.5602 - loss: 1.1041 - val_accuracy: 0.5388 - val_loss: 1.1392\n",
      "Epoch 4/5\n",
      "1430/1430 - 85s - 59ms/step - accuracy: 0.5854 - loss: 1.0484 - val_accuracy: 0.5420 - val_loss: 1.1349\n",
      "Epoch 5/5\n",
      "1430/1430 - 54s - 38ms/step - accuracy: 0.6048 - loss: 1.0016 - val_accuracy: 0.5413 - val_loss: 1.1450\n",
      "Test Accuracy: 0.54\n",
      "\u001b[1m716/716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.40      0.42      3375\n",
      "           1       0.39      0.45      0.42      3214\n",
      "           2       0.70      0.64      0.67      3274\n",
      "           3       0.87      0.88      0.87      3325\n",
      "           4       0.43      0.41      0.42      3241\n",
      "           5       0.42      0.53      0.47      3209\n",
      "           6       0.58      0.47      0.52      3243\n",
      "\n",
      "    accuracy                           0.54     22881\n",
      "   macro avg       0.55      0.54      0.54     22881\n",
      "weighted avg       0.55      0.54      0.54     22881\n",
      "\n",
      "ROC-AUC: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Split the resampled data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=64))  # Embedding layer without input_length\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))  # Convolutional layer\n",
    "model.add(MaxPooling1D(pool_size=2))  # Max pooling layer\n",
    "model.add(Dropout(0.5))  # Dropout layer\n",
    "model.add(Flatten())  # Flatten the output\n",
    "model.add(Dense(32, activation='relu'))  # Fully connected layer\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class, y_pred))\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c5d2e0-0f6f-4f81-a1f3-6bb0224794d3",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacc14c-ec8c-48aa-a008-7421c2e9eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class KerasClassifierCustom(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, vocab_size, embedding_dim, conv_filters, kernel_size, pool_size, dropout_rate, dense_units, num_classes, epochs=5, batch_size=64, verbose=2):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.conv_filters = conv_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_size = pool_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dense_units = dense_units\n",
    "        self.num_classes = num_classes\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=max_len))\n",
    "        model.add(Conv1D(filters=self.conv_filters, kernel_size=self.kernel_size, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=self.pool_size))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.dense_units, activation='relu'))\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = self.build_model()\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.model.predict(X), axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.model.evaluate(X, y, verbose=0)[1]\n",
    "\n",
    "param_grid = {\n",
    "    'vocab_size': [1000, 2000],\n",
    "    'embedding_dim': [50, 64],\n",
    "    'conv_filters': [64, 128],\n",
    "    'kernel_size': [3, 5],\n",
    "    'pool_size': [2, 3],\n",
    "    'dropout_rate': [0.3, 0.5],\n",
    "    'dense_units': [16, 32]\n",
    "}\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_pad, y_numeric)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "model = KerasClassifierCustom(\n",
    "    vocab_size=2000,\n",
    "    embedding_dim=64,\n",
    "    conv_filters=128,\n",
    "    kernel_size=5,\n",
    "    pool_size=2,\n",
    "    dropout_rate=0.5,\n",
    "    dense_units=32,\n",
    "    num_classes=y_train.shape[1]\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, scoring='accuracy')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_result.best_params_)\n",
    "print(\"Best Score:\", grid_result.best_score_)\n",
    "\n",
    "best_model = grid_result.best_estimator_\n",
    "loss, accuracy = best_model.model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy:.2f}')\n",
    "\n",
    "y_pred_prob = best_model.model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_class, y_pred))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e5fa6-9f15-4296-add3-a067e659c550",
   "metadata": {},
   "source": [
    "# checking GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64b78fae-f01f-492b-b0db-6048b3df8a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50d1721b-bb6f-4af5-99ea-91187291270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b7cd5dc-7f80-4ef8-a2ec-2c273bae5f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2249802e-9b2d-4577-a141-e19a93044e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
